{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# INTRODUCTION TO A RAG-IMPLEMENTATION",
   "id": "839ad714984b188f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T12:10:55.927395Z",
     "start_time": "2025-01-11T12:10:54.699973Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load an open-source model\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:10:58.625830Z",
     "start_time": "2025-01-11T12:10:55.936004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add a pad_token_id if necessary\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Simple prompt\n",
    "prompt = \"Who's Charles Darwin\"\n",
    "\n",
    "# Tokenization with attention_mask and padding\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Text generation\n",
    "output = model.generate(\n",
    "    inputs.input_ids,\n",
    "    max_length=100,  # Maximum length of the generated text\n",
    "    num_return_sequences=1,  # Number of text sequences generated\n",
    "    temperature=0.7,  # Controls the creativity of the model\n",
    "    do_sample=True,  # Enables sampling\n",
    "    pad_token_id=tokenizer.eos_token_id  # Defines a padding token\n",
    ")\n",
    "\n",
    "# Decode the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Generated text:\")\n",
    "print(generated_text)\n"
   ],
   "id": "fa6c8f2596b89830",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte généré :\n",
      "Who's Charles Darwin?\"\n",
      "\n",
      "\"I don't know.\"\n",
      "\n",
      "\"Not exactly. But I do know that if you wanted to be a man, you'd have to learn the language. But you'd be the most difficult man to learn. So you're going to learn to speak English.\"\n",
      "\n",
      "\"English?\"\n",
      "\n",
      "\"Yes. And I'm going to learn how to read, how to write, how to read and write.\"\n",
      "\n",
      "\"Why are you so interested in\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PDF READER\n",
   "id": "da3fc073808c3246"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:10:58.890144Z",
     "start_time": "2025-01-11T12:10:58.711286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Load the PDF\n",
    "pdf_path = \"/data/health_systems/Psychology_is_improving_brain_health_and_aging.pdf\"\n",
    "reader = PdfReader(pdf_path)\n",
    "\n",
    "# Extract all the text\n",
    "document_text = \"\"\n",
    "for page in reader.pages:\n",
    "    document_text += page.extract_text()\n",
    "\n",
    "# Preview the extracted text\n",
    "print(\"Extracted text (preview):\", document_text[:500])\n",
    "\n",
    "# Print the total character count\n",
    "print(\"Total character count:\", len(document_text))\n",
    "\n",
    "def split_text(text, max_length=100):\n",
    "    sentences = text.split(\". \")\n",
    "    chunks, chunk = [], []\n",
    "    current_length = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        chunk.append(sentence)\n",
    "        current_length += len(sentence.split())\n",
    "        if current_length >= max_length:\n",
    "            chunks.append(\". \".join(chunk))\n",
    "            chunk, current_length = [], 0\n",
    "\n",
    "    if chunk:\n",
    "        chunks.append(\". \".join(chunk))\n",
    "    return chunks\n",
    "\n",
    "segments = split_text(document_text)\n",
    "print(\"Number of segments:\", len(segments))\n"
   ],
   "id": "4dd216cfc7f31671",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/health_systems/Psychology_is_improving_brain_health_and_aging.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Charger le PDF\u001B[39;00m\n\u001B[1;32m      4\u001B[0m pdf_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/data/health_systems/Psychology_is_improving_brain_health_and_aging.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 5\u001B[0m reader \u001B[38;5;241m=\u001B[39m \u001B[43mPdfReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpdf_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Extraire tout le texte\u001B[39;00m\n\u001B[1;32m      8\u001B[0m document_text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.8/site-packages/PyPDF2/_reader.py:317\u001B[0m, in \u001B[0;36mPdfReader.__init__\u001B[0;34m(self, stream, strict, password)\u001B[0m\n\u001B[1;32m    311\u001B[0m     logger_warning(\n\u001B[1;32m    312\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPdfReader stream/file object is not in binary mode. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    313\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt may not be read correctly.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    314\u001B[0m         \u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m    315\u001B[0m     )\n\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(stream, (\u001B[38;5;28mstr\u001B[39m, Path)):\n\u001B[0;32m--> 317\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fh:\n\u001B[1;32m    318\u001B[0m         stream \u001B[38;5;241m=\u001B[39m BytesIO(fh\u001B[38;5;241m.\u001B[39mread())\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(stream)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/data/health_systems/Psychology_is_improving_brain_health_and_aging.pdf'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def read_text_file(file_path):\n",
    "    \"\"\"Read the content of a text file\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def split_text_by_characters(text, max_length=1000):\n",
    "    \"\"\"Split the text into chunks of maximum length (in characters)\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + max_length\n",
    "        chunks.append(text[start:end])\n",
    "        start = end\n",
    "    return chunks\n",
    "\n",
    "# Example usage with a text file\n",
    "file_path = \"/data/Darwin_data/darwin\"  # Replace with the path to your file\n",
    "document_text = read_text_file(file_path)\n",
    "\n",
    "# Split the text into chunks (e.g., 1000 characters per chunk)\n",
    "segments = split_text_by_characters(document_text, max_length=1000)\n",
    "\n",
    "# Display the number of segments created and a preview of the first segment\n",
    "print(f\"Number of segments created: {len(segments)}\")\n",
    "print(\"Preview of the first segment:\", segments[0][:200])  # Display a preview of 200 characters from the first segment\n"
   ],
   "id": "e68361b5a7d272f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# WIKIPEDIA READER",
   "id": "a3744265ee5b4ae7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:14:25.719595Z",
     "start_time": "2025-01-11T12:14:25.701627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def clean_wikipedia_text(text):\n",
    "    \"\"\"\n",
    "    Cleans Wikipedia text:\n",
    "    - Removes <ref> tags, {{...}} templates, and HTML tags.\n",
    "    - Removes [[...]] while keeping their content.\n",
    "    - Reduces multiple spaces.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"<ref[^>]*>.*?</ref>\", \"\", text, flags=re.DOTALL)  # Remove <ref> tags\n",
    "    text = re.sub(r\"{{[^}]*}}\", \"\", text)  # Remove {{...}} templates\n",
    "    text = re.sub(r\"<[^>]*>\", \"\", text)  # Remove HTML tags\n",
    "    text = re.sub(r\"\\[\\[([^|\\]]+\\|)?([^\\]]+)\\]\\]\", r\"\\2\", text)  # Remove [[]] while keeping the content\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Reduce multiple spaces\n",
    "    return text\n",
    "\n",
    "def split_text(text, max_length=1000):\n",
    "    \"\"\"\n",
    "    Splits the text into segments with a given maximum length.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    while len(text) > max_length:\n",
    "        split_index = text[:max_length].rfind(\".\")\n",
    "        if split_index == -1:  # If no period is found, cut abruptly\n",
    "            split_index = max_length\n",
    "        segments.append(text[:split_index+1].strip())\n",
    "        text = text[split_index+1:].strip()\n",
    "    if text:  # Add the last segment\n",
    "        segments.append(text)\n",
    "    return segments\n",
    "\n",
    "# Example usage\n",
    "input_file_path = \"/Users/enzosebiane/PycharmProjects/BigDataProject/Darwin_data/darwin\"  # Path to your text file\n",
    "\n",
    "# Read and clean the text\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "cleaned_text = clean_wikipedia_text(raw_text)\n",
    "segments = split_text(cleaned_text, max_length=500)\n",
    "\n",
    "# Display the number of segments created and a preview of the first segment\n",
    "print(f\"Number of segments created: {len(segments)}\")\n",
    "print(\"Preview of the first segment:\", segments[0][:200])  # Display a preview of 200 characters from the first segment\n"
   ],
   "id": "333a307b396ede85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de segments créés : 165\n",
      "Extrait du premier segment : | image = Charles Darwin seated crop.jpg | alt = Three quarter length studio photo showing Darwin's characteristic large forehead and bushy eyebrows with deep set eyes, pug nose and mouth set in a det\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Context (RAG)",
   "id": "b03849e5c474d9ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:14:40.914854Z",
     "start_time": "2025-01-11T12:14:36.042863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Convert the segments into embeddings\n",
    "embeddings = embedder.encode(segments)\n",
    "\n",
    "# Create a FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  # Using L2 distance (Euclidean distance) for similarity\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"FAISS index created with\", index.ntotal, \"documents\")  # Display the number of documents in the index\n",
    "\n"
   ],
   "id": "184743802003435a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index FAISS créé avec 165 documents\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:14:47.911622Z",
     "start_time": "2025-01-11T12:14:47.493663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# User query\n",
    "query = \"Who's Charles Darwin\"\n",
    "\n",
    "# Convert the query into an embedding\n",
    "query_embedding = embedder.encode([query])\n",
    "\n",
    "# Perform the search in the index\n",
    "k = 2  # Number of results to retrieve\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Retrieve the relevant segments based on the indices\n",
    "retrieved_segments = [segments[i] for i in indices[0]]\n",
    "print(\"Relevant segments:\", retrieved_segments)  # Display the retrieved relevant segments\n",
    "\n"
   ],
   "id": "ac1179fa3714c405",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segments pertinents : [\"| caption = Darwin, , when he was preparing ''On the Origin of Species'' | birth_name = Charles Robert Darwin | birth_date = | birth_place = Shrewsbury, Shropshire, England | death_date = | death_place = Down House, Down, Kent, England | resting_place = Westminster Abbey | alma_mater = | known_for = Natural selection | spouse = | children = 10, including William, Henrietta, George, Francis, Leonard and Horace | parents = | family = Darwin–Wedgwood | awards = ; 12 February 1809&nbsp;– 19 April 188\", \"==Biography== ===Early life and education=== Darwin was born in Shrewsbury, Shropshire, on 12 February 1809, at his family's home, The Mount. He was the fifth of six children of wealthy society doctor and financier Robert Darwin and Susannah Darwin (née Wedgwood). His grandfathers Erasmus Darwin and Josiah Wedgwood were both prominent abolitionists.\"]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:15:20.283539Z",
     "start_time": "2025-01-11T12:15:16.650785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the LLM model\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Define the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Prepare the context for generation\n",
    "context = \" \".join(retrieved_segments)\n",
    "prompt = f\"Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "\n",
    "# Tokenize with padding\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "output = model.generate(\n",
    "    inputs.input_ids,\n",
    "    max_length=300,  # Maximum length of the generated output\n",
    "    num_return_sequences=1,  # Number of generated texts\n",
    "    temperature=0.7,  # Controls the creativity of the output\n",
    "    do_sample=True,  # Enables sampling\n",
    "    pad_token_id=tokenizer.eos_token_id  # Define the padding token ID\n",
    ")\n",
    "\n",
    "# Display the generated answer\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Generated answer:\")\n",
    "print(response)\n"
   ],
   "id": "99077aed5e126ad4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse générée :\n",
      "Contexte : | caption = Darwin,, when he was preparing ''On the Origin of Species'' | birth_name = Charles Robert Darwin | birth_date = | birth_place = Shrewsbury, Shropshire, England | death_date = | death_place = Down House, Down, Kent, England | resting_place = Westminster Abbey | alma_mater = | known_for = Natural selection | spouse = | children = 10, including William, Henrietta, George, Francis, Leonard and Horace | parents = | family = Darwin–Wedgwood | awards = ; 12 February 1809&nbsp;– 19 April 188 ==Biography== ===Early life and education=== Darwin was born in Shrewsbury, Shropshire, on 12 February 1809, at his family's home, The Mount. He was the fifth of six children of wealthy society doctor and financier Robert Darwin and Susannah Darwin (née Wedgwood). His grandfathers Erasmus Darwin and Josiah Wedgwood were both prominent abolitionists.\n",
      "\n",
      "Question : Who's Charles Darwin\n",
      "\n",
      "Réponse : Darwin had two sons: Charles, who was born on 13 April 1809; and Charles, born on 13 February 1812.\n",
      "\n",
      "Question : Who's Charles Darwin's father was?\n",
      "\n",
      "Réponse : (1) Charles Darwin, born in 1809. (2) Charles Darwin\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
