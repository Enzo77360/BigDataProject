{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# INTRODUCTION TO A RAG-IMPLEMENTATION",
   "id": "839ad714984b188f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T12:10:55.927395Z",
     "start_time": "2025-01-11T12:10:54.699973Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Charger un modèle open-source\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:10:58.625830Z",
     "start_time": "2025-01-11T12:10:55.936004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ajouter un pad_token_id si nécessaire\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Prompt simple\n",
    "prompt = \"Who's Charles Darwin\"\n",
    "\n",
    "# Tokenisation avec attention_mask et padding\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Génération\n",
    "output = model.generate(\n",
    "    inputs.input_ids,\n",
    "    max_length=100,  # Longueur max de la génération\n",
    "    num_return_sequences=1,  # Nombre de textes générés\n",
    "    temperature=0.7,  # Contrôle de la créativité\n",
    "    do_sample=True,  # Active le sampling\n",
    "    pad_token_id=tokenizer.eos_token_id  # Définit un token de padding\n",
    ")\n",
    "\n",
    "# Décodage du texte généré\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Texte généré :\")\n",
    "print(generated_text)"
   ],
   "id": "fa6c8f2596b89830",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte généré :\n",
      "Who's Charles Darwin?\"\n",
      "\n",
      "\"I don't know.\"\n",
      "\n",
      "\"Not exactly. But I do know that if you wanted to be a man, you'd have to learn the language. But you'd be the most difficult man to learn. So you're going to learn to speak English.\"\n",
      "\n",
      "\"English?\"\n",
      "\n",
      "\"Yes. And I'm going to learn how to read, how to write, how to read and write.\"\n",
      "\n",
      "\"Why are you so interested in\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PDF READER\n",
   "id": "da3fc073808c3246"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:10:58.890144Z",
     "start_time": "2025-01-11T12:10:58.711286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Charger le PDF\n",
    "pdf_path = \"/data/health_systems/Psychology_is_improving_brain_health_and_aging.pdf\"\n",
    "reader = PdfReader(pdf_path)\n",
    "\n",
    "# Extraire tout le texte\n",
    "document_text = \"\"\n",
    "for page in reader.pages:\n",
    "    document_text += page.extract_text()\n",
    "\n",
    "# Afficher un aperçu du texte extrait\n",
    "print(\"Texte extrait (aperçu) :\", document_text[:500])\n",
    "\n",
    "# Afficher le nombre total de caractères\n",
    "print(\"Nombre total de caractères :\", len(document_text))\n",
    "\n",
    "def split_text(text, max_length=100):\n",
    "    sentences = text.split(\". \")\n",
    "    chunks, chunk = [], []\n",
    "    current_length = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        chunk.append(sentence)\n",
    "        current_length += len(sentence.split())\n",
    "        if current_length >= max_length:\n",
    "            chunks.append(\". \".join(chunk))\n",
    "            chunk, current_length = [], 0\n",
    "\n",
    "    if chunk:\n",
    "        chunks.append(\". \".join(chunk))\n",
    "    return chunks\n",
    "\n",
    "segments = split_text(document_text)\n",
    "print(\"Nombre de segments :\", len(segments))\n"
   ],
   "id": "4dd216cfc7f31671",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/health_systems/Psychology_is_improving_brain_health_and_aging.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Charger le PDF\u001B[39;00m\n\u001B[1;32m      4\u001B[0m pdf_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/data/health_systems/Psychology_is_improving_brain_health_and_aging.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 5\u001B[0m reader \u001B[38;5;241m=\u001B[39m \u001B[43mPdfReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpdf_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Extraire tout le texte\u001B[39;00m\n\u001B[1;32m      8\u001B[0m document_text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/BigDataProject/.venv/lib/python3.8/site-packages/PyPDF2/_reader.py:317\u001B[0m, in \u001B[0;36mPdfReader.__init__\u001B[0;34m(self, stream, strict, password)\u001B[0m\n\u001B[1;32m    311\u001B[0m     logger_warning(\n\u001B[1;32m    312\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPdfReader stream/file object is not in binary mode. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    313\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt may not be read correctly.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    314\u001B[0m         \u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m    315\u001B[0m     )\n\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(stream, (\u001B[38;5;28mstr\u001B[39m, Path)):\n\u001B[0;32m--> 317\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fh:\n\u001B[1;32m    318\u001B[0m         stream \u001B[38;5;241m=\u001B[39m BytesIO(fh\u001B[38;5;241m.\u001B[39mread())\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(stream)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/data/health_systems/Psychology_is_improving_brain_health_and_aging.pdf'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def read_text_file(file_path):\n",
    "    \"\"\"Lire le contenu d'un fichier texte\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def split_text_by_characters(text, max_length=1000):\n",
    "    \"\"\"Diviser le texte en segments de longueur maximale (en caractères)\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + max_length\n",
    "        chunks.append(text[start:end])\n",
    "        start = end\n",
    "    return chunks\n",
    "\n",
    "# Exemple d'utilisation avec un fichier texte\n",
    "file_path = \"/data/Darwin_data/darwin\"  # Remplacez par le chemin de votre fichier\n",
    "document_text = read_text_file(file_path)\n",
    "\n",
    "# Diviser le texte en segments (par exemple, 1000 caractères par segment)\n",
    "segments = split_text_by_characters(document_text, max_length=1000)\n",
    "\n",
    "# Afficher le nombre de segments créés et un extrait du premier segment\n",
    "print(f\"Nombre de segments créés : {len(segments)}\")\n",
    "print(\"Extrait du premier segment :\", segments[0][:200])  # Afficher un extrait de 200 caractères du premier segment\n"
   ],
   "id": "e68361b5a7d272f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# WIKIPEDIA READER",
   "id": "a3744265ee5b4ae7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:14:25.719595Z",
     "start_time": "2025-01-11T12:14:25.701627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def clean_wikipedia_text(text):\n",
    "    \"\"\"\n",
    "    Nettoie un texte Wikipédia :\n",
    "    - Supprime les balises <ref>, les modèles {{...}} et les balises HTML.\n",
    "    - Supprime les doubles crochets [[...]] tout en conservant leur contenu.\n",
    "    - Réduit les espaces multiples.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"<ref[^>]*>.*?</ref>\", \"\", text, flags=re.DOTALL)  # Supprimer les balises <ref>\n",
    "    text = re.sub(r\"{{[^}]*}}\", \"\", text)  # Supprimer les modèles {{...}}\n",
    "    text = re.sub(r\"<[^>]*>\", \"\", text)  # Supprimer les balises HTML\n",
    "    text = re.sub(r\"\\[\\[([^|\\]]+\\|)?([^\\]]+)\\]\\]\", r\"\\2\", text)  # Supprimer les [[]] tout en conservant le contenu\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Réduire les espaces multiples\n",
    "    return text\n",
    "\n",
    "def split_text(text, max_length=1000):\n",
    "    \"\"\"\n",
    "    Divise le texte en segments d'une longueur maximale donnée.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    while len(text) > max_length:\n",
    "        split_index = text[:max_length].rfind(\".\")\n",
    "        if split_index == -1:  # Si aucun point trouvé, couper brutalement\n",
    "            split_index = max_length\n",
    "        segments.append(text[:split_index+1].strip())\n",
    "        text = text[split_index+1:].strip()\n",
    "    if text:  # Ajouter le dernier segment\n",
    "        segments.append(text)\n",
    "    return segments\n",
    "\n",
    "# Exemple d'utilisation\n",
    "input_file_path = \"/Users/enzosebiane/PycharmProjects/BigDataProject/Darwin_data/darwin\"  # Chemin vers votre fichier texte\n",
    "\n",
    "# Lire et nettoyer le texte\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "cleaned_text = clean_wikipedia_text(raw_text)\n",
    "segments = split_text(cleaned_text, max_length=500)\n",
    "\n",
    "# Afficher le nombre de segments créés et un extrait du premier segment\n",
    "print(f\"Nombre de segments créés : {len(segments)}\")\n",
    "print(\"Extrait du premier segment :\", segments[0][:200])  # Afficher un extrait de 200 caractères du premier segment\n"
   ],
   "id": "333a307b396ede85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de segments créés : 165\n",
      "Extrait du premier segment : | image = Charles Darwin seated crop.jpg | alt = Three quarter length studio photo showing Darwin's characteristic large forehead and bushy eyebrows with deep set eyes, pug nose and mouth set in a det\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Context (RAG)",
   "id": "b03849e5c474d9ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:14:40.914854Z",
     "start_time": "2025-01-11T12:14:36.042863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Charger le modèle d'embedding\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Convertir les segments en embeddings\n",
    "embeddings = embedder.encode(segments)\n",
    "\n",
    "# Créer un index FAISS\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"Index FAISS créé avec\", index.ntotal, \"documents\")\n"
   ],
   "id": "184743802003435a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index FAISS créé avec 165 documents\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:14:47.911622Z",
     "start_time": "2025-01-11T12:14:47.493663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Question utilisateur\n",
    "query =  \"Who's Charles Darwin\"\n",
    "\n",
    "query_embedding = embedder.encode([query])\n",
    "\n",
    "# Recherche dans l'index\n",
    "k = 2 # Nombre de résultats à récupérer\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Récupérer les documents pertinents\n",
    "retrieved_segments = [segments[i] for i in indices[0]]\n",
    "print(\"Segments pertinents :\", retrieved_segments)\n"
   ],
   "id": "ac1179fa3714c405",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segments pertinents : [\"| caption = Darwin, , when he was preparing ''On the Origin of Species'' | birth_name = Charles Robert Darwin | birth_date = | birth_place = Shrewsbury, Shropshire, England | death_date = | death_place = Down House, Down, Kent, England | resting_place = Westminster Abbey | alma_mater = | known_for = Natural selection | spouse = | children = 10, including William, Henrietta, George, Francis, Leonard and Horace | parents = | family = Darwin–Wedgwood | awards = ; 12 February 1809&nbsp;– 19 April 188\", \"==Biography== ===Early life and education=== Darwin was born in Shrewsbury, Shropshire, on 12 February 1809, at his family's home, The Mount. He was the fifth of six children of wealthy society doctor and financier Robert Darwin and Susannah Darwin (née Wedgwood). His grandfathers Erasmus Darwin and Josiah Wedgwood were both prominent abolitionists.\"]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T12:15:20.283539Z",
     "start_time": "2025-01-11T12:15:16.650785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Charger le modèle LLM\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Définir le token de remplissage\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Préparer le contexte pour la génération\n",
    "context = \" \".join(retrieved_segments)\n",
    "prompt = f\"Contexte : {context}\\n\\nQuestion : {query}\\n\\nRéponse :\"\n",
    "\n",
    "# Tokenisation avec padding\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "output = model.generate(\n",
    "    inputs.input_ids,\n",
    "    max_length = 300,  # Longueur max de la génération\n",
    "    num_return_sequences=1,  # Nombre de textes générés\n",
    "    temperature=0.7,  # Contrôle de la créativité\n",
    "    do_sample=True,  # Active le sampling\n",
    "    pad_token_id=tokenizer.eos_token_id  # Définit un token de padding\n",
    ")\n",
    "\n",
    "\n",
    "# Afficher la réponse générée\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Réponse générée :\")\n",
    "print(response)"
   ],
   "id": "99077aed5e126ad4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse générée :\n",
      "Contexte : | caption = Darwin,, when he was preparing ''On the Origin of Species'' | birth_name = Charles Robert Darwin | birth_date = | birth_place = Shrewsbury, Shropshire, England | death_date = | death_place = Down House, Down, Kent, England | resting_place = Westminster Abbey | alma_mater = | known_for = Natural selection | spouse = | children = 10, including William, Henrietta, George, Francis, Leonard and Horace | parents = | family = Darwin–Wedgwood | awards = ; 12 February 1809&nbsp;– 19 April 188 ==Biography== ===Early life and education=== Darwin was born in Shrewsbury, Shropshire, on 12 February 1809, at his family's home, The Mount. He was the fifth of six children of wealthy society doctor and financier Robert Darwin and Susannah Darwin (née Wedgwood). His grandfathers Erasmus Darwin and Josiah Wedgwood were both prominent abolitionists.\n",
      "\n",
      "Question : Who's Charles Darwin\n",
      "\n",
      "Réponse : Darwin had two sons: Charles, who was born on 13 April 1809; and Charles, born on 13 February 1812.\n",
      "\n",
      "Question : Who's Charles Darwin's father was?\n",
      "\n",
      "Réponse : (1) Charles Darwin, born in 1809. (2) Charles Darwin\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "36c5ee3fdd049816"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
